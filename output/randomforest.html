<!DOCTYPE html>
<html lang="en">
<head>
 <title>Random Forest Classifier</title>
 <!-- Latest compiled and minified Bootstrap CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<!--link rel="stylesheet" href="theme/css/rdark.css" /-->
<link rel="stylesheet" type="text/css" href="theme/css/main.css" />

    <!-- Using MathJax, with the delimiters $ -->
<!-- Conflict with pygments for the .mo and .mi -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
    styles: {
    ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
    },
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']],processEscapes: true}
    });
  </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

</head>
<body>
    
    <title></title>
    
<nav >
  <div class="container" id="navbar">
    <div class="navbar-header">
      <a class="navbar-brand" href="index.html">Portfolio</a>
    </div>
    <ul class="nav navbar-nav">
            <li><b>|</b></li>
            <li>
                <a href="./articles.html">Articles</a></li>
            <li><b>|</b></li>
            <li>
                <a href="./cv.html">CV</a></li>
            <li><b>|</b></li>
            <li>
                <a href="./hobby.html">Hobby</a></li>
    </ul>
  </div>
</nav>
    
    
<!-- Main Content -->
 <div class="container" id="main">
<div class="row">
 <div class="col-md-12">
        <h1><strong>Article | </strong>Random Forest Classifier</h1>
     <br>
     <h4 style="padding-left: 7%; padding-right: 7%;"><p>Describes the Random Forest Classifier and how you can use it with python</p></h4>
     
     
     <div class="content">
         <hr style="border-width: thin; border-color: black">
         
        <p>
            <img src="theme/img/date3.png" style="height:25px" class="icon">  
            <strong> | Article Year -- </strong> 2020</p>
         <p>
                <img src="theme/img/skills2.png" style="height:25px" class="icon">             
             <strong> | Tags -- </strong>
        <span>random forest</span> | 
        <span>trees</span> | 
        <span>decision trees</span> | 
        <span>machine learning</span> | 
        <span>ml</span> | 
    </p>
     


    


         
        
         
         
         
         <hr style="border-width: thin; border-color: black; padding-bottom: 4%;">

         <p><ul>
<li>Random Forests are built from decision trees.</li>
<li>Combines the simplicity of decision trees with some flexibility to achieve a better accuracy.</li>
</ul>
<p><strong>How to create a Random Forest:</strong></p>
<ol>
<li>Create a bootstrapped dataset<ul>
<li>Randomly select samples from the original dataset<ul>
<li>You may pick the same sample more than once</li>
</ul>
</li>
</ul>
</li>
<li>Create a decision tree using the bootstrapped dataset<ul>
<li>At each step, select a random number of columns (variables)<ul>
<li>E.g. we select 2 out of 4 columns to use.</li>
<li>A good starting point is the square of the number of variables</li>
</ul>
</li>
<li>Select the best column to use as the root node (first step)</li>
<li>Select 2 new random columns from the remaining as candidates</li>
</ul>
</li>
<li>Repeat step 2 so as to create multiple decision trees from a bootstrapped dataset</li>
<li>The resulting trees will look different from one another. The variety of trees is what makes Random Forest effective.</li>
<li>Run the out-of-bag dataset through all the trees.</li>
<li>Accuracy can be measured by the proportion of out-of-bag samples that were correctly classified.</li>
<li>You can now create Random Forest Trees using a different number of columns at each step, and check which one has the best accuracy. </li>
<li>To predict from new data, run the data through all the trees and see which category got the most votes.</li>
</ol>
<p><strong>Keywords:</strong></p>
<ul>
<li>Bagging: Bootstrapping the data using the aggregate to make a decision</li>
<li>Out-of-bag Dataset: The data that is left over after bootstrapping the dataset</li>
<li>Out-of-bag Error: The proportion of out-of-bag samples that were incorrectly classified.</li>
</ul>
<p><strong>How to deal with missing data?</strong></p>
<p>Data can be missing either in the original dataset (training data), or in the new data you want to categorize.</p>
<ol>
<li>Make an initial guess based on the most common values in the column.</li>
<li>Refine your guesses by determining which samples (rows) are similar<ul>
<li>Build a Random Forest</li>
<li>Run all data through all the trees<ul>
<li>If two or more samples end up in the same leaf node, that means they are similar.</li>
<li>Use a proximity matrix to keep track of the similar samples. Each numbered column/row corresponds to a sample. A value of 1 says that they are similar.</li>
<li>Add to the proximity matrix for each tree the data is run through.</li>
<li>If the same samples are similar in other trees, increment the value by 1 for each tree.</li>
<li>After all the trees have been run through, divide each value by the total number of trees.</li>
<li>Use the proximity values for the sample with missing data (4) to make a better guess.</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>How to make a better guess using proximity matrix?</strong></p>
<ol>
<li>Find the weighted frequency that each other value in the column have<ul>
<li>Frequency = (Number of time value occurs) / (Total number of values in column)</li>
<li>Weight = (Proximity of the value)  / (All proximities)<ul>
<li>Proximity of the value: The number given in the proximity matrix for that value. E.g. The third column in sample 2 will have a proximity value of 0.1. If more samples have the same value, sum the proximites.</li>
<li>All proximities: Sum all the proximity values for the sample that we are making a guess for.</li>
</ul>
</li>
</ul>
</li>
<li>Use the value that had the highest weighted frequency as the new guess.</li>
</ol>
<p><strong>How to make a better guess for continuous data using proximity matrix?</strong></p>
<ol>
<li>Use the weighted average as the refined guess.<ul>
<li>Weighted average = Value of the column * Weight (same as previously described)</li>
<li>Take the weighted average for each value in the column and sum them.</li>
<li>Use the result of the equation as the new refined guess.</li>
</ul>
</li>
</ol>
<p><strong>Repeat</strong> each of these steps for making a more refined guess, by building a new Random Forest and running the data through them and making a proximity matrix. Do this until there is no change made in the guess.</p>
<p><strong>How to make a guess for missing data in a new sample?</strong></p>
<ol>
<li>Create several copies of the sample - each one with a different category.</li>
<li>Use the same iterative method as for the original samples for each of these new samples. You now have a guess for the missing data in each sample.</li>
<li>Check which one of the samples is being correctly labeled the most times with the new guess. </li>
<li>The sample which is being correctly labeled the most times is the winner and the category for the new sample can be determined.</li>
</ol>
<p><strong>How to measure distance using proximity matrix?</strong></p>
<ol>
<li>Distance = 1 - proximity values.<ul>
<li>For each proximity value, subtract it from 1 and input the new value into the matrix.</li>
<li>The higher the number, the more far away the samples are.</li>
<li>From the matrix we can create an MDS plot (Multidimensional Scaling) that better shows the distances.</li>
</ul>
</li>
</ol>
<p><strong>Fact:</strong> If we can make a tree from some data, we can show how the samples are related using an MDS plot. </p>
<p><strong>How to use a Random Forest Classifier in python?</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1">#Import Random Forest Model</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1">#Create a Gaussian Classifier</span>
<span class="n">clf</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1">#Train the model using the training sets</span>
<span class="n">y_pred</span> <span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="n">y_pred</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1">#Import scikit-learn metrics module for accuracy calculation</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="c1"># Model Accuracy, how often is the classifier correct?</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="c1">#Use the model to make predictions on new data</span>
<span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
</code></pre></div>


<p><strong>Important Hyperparameters:</strong></p>
<ul>
<li>n_estimators: The total number of trees to build.</li>
<li>Criterion: Can be “gini” or “entropy”. Determines what function to use when making splits in the tree.</li>
<li>Max_Depth: The maximum number of nodes from the root to the leaf nodes.</li>
<li>Max Features: How to determine the best number of features when building the trees. </li>
</ul></p>
     </div>
 </div>
</div>
</div>
<!-- End of Main Content --> 
   
    
<!--  Footer   -->
    <div class="container" id="footer">
        <ul>
            <li>
                <a href="mailto:thomb@hotmail.dk">
                    <img src="theme/img/email.png" style="height:30px" class="icon">
                </a> 
            
            </li>   
            <li><b>|</b></li>
            <li>                
                <a target="_blank" href="https://www.linkedin.com/in/thomas-brunbjerg-8a6ba8137/">
                    <img src="theme/img/linkedin.jpg" style="height:30px" class="icon">
                </a> 
            </li>
            <li><b>|</b></li>
                <li>
                <a target="_blank" href="https://github.com/ThomB93">
                    <img src="theme/img/github.png" style="height:30px" class="icon">
                </a>
            </li>
            <li><b>|</b></li>
                <li>
                <a target="_blank" href="https://www.youtube.com/channel/UC3rc5zj8sLo_HiPXCxb0y4g">
                    <img src="theme/img/youtube.png" style="height:30px" class="icon">
                </a>
            </li>
        </ul>
    </div>
    
<!--  End Footer  -->
    
</body>
</html>